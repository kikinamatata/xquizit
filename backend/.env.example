# ============================================================================
# XQUIZIT - AI Interview Screening System Configuration
# ============================================================================

# ============================================================================
# GOOGLE GEMINI API (Required)
# ============================================================================
# Get your API key from: https://aistudio.google.com/app/apikey
GEMINI_API_KEY=your_google_gemini_api_key_here
# Gemini model to use (default: gemini-2.5-flash)
GEMINI_MODEL=gemini-2.5-flash

# LLM Optimization Parameters
GEMINI_THINKING_BUDGET=1024         # 0 = disabled, higher = more thinking time
GEMINI_INCLUDE_THOUGHTS=false     # Include reasoning in responses (for debugging)
GEMINI_MAX_OUTPUT_TOKENS=1024     # Limit response size
GEMINI_TEMPERATURE=0.7            # 0.0 = deterministic, 1.0 = creative

# ============================================================================
# INDIC PARLER-TTS (Text-to-Speech with Indian English Support)
# ============================================================================
# Model: ai4bharat/indic-parler-tts (900M parameters, native Indian English)
# Note: This model is GATED - requires HuggingFace authentication
# 1. Create account at https://huggingface.co/join
# 2. Request access at https://huggingface.co/ai4bharat/indic-parler-tts
# 3. Login with: huggingface-cli login
#    (Get token from https://huggingface.co/settings/tokens)

# Model ID (gated model - requires authentication)
PARLER_MODEL_ID=ai4bharat/indic-parler-tts

# Device: "cuda" (GPU), "cpu", or "auto" (auto-detect)
PARLER_DEVICE=cuda

# Voice description (natural language description of desired voice)
# Recommended voices for Indian English: "Thoma" (male) or "Mary" (female)
# Format: "[Speaker] speaks with [pace] in [recording quality] with [expressivity]"
PARLER_VOICE_DESCRIPTION=Thoma speaks with a clear, moderate pace in a close recording with minimal background noise and a slightly expressive tone

# Streaming latency (target seconds for first audio chunk)
# 0.3s = 300ms TTFA (time-to-first-audio) - excellent for real-time
# Lower values = faster response, but ensure GPU can keep up
PARLER_PLAY_STEPS_IN_S=0.3

# Generation parameters
PARLER_TEMPERATURE=1.0            # Sampling temperature (1.0 recommended for Parler-TTS)
PARLER_TOP_P=1.0                  # Nucleus sampling threshold
PARLER_REPETITION_PENALTY=1.0     # Token repetition penalty
PARLER_MIN_NEW_TOKENS=10          # Minimum tokens to generate (recommended by Parler team)
PARLER_MAX_NEW_TOKENS=2000        # Maximum tokens (~22 seconds of audio at 91 fps)

# Performance optimization (GPU/Linux)
# torch.compile() requires Triton (Linux only, doesn't work on Windows)
# For Linux GPU setup with CUDA 12.8: set to true for ~4x speedup
# For Windows or CPU-only: set to false
PARLER_ENABLE_COMPILE=true        # Enable torch.compile() for ~4x speedup (requires Triton on Linux)

# GPU Optimization Settings (Linux CUDA 12.8+ only)
# These settings are automatically used when CUDA is available
# Flash Attention 2: Provides ~1.4x additional speedup (install: pip install flash-attn)
# Combined with torch.compile(): ~5-6x total speedup over base GPU performance
# Expected Time-to-First-Audio (TTFA): <200ms (from ~300ms base)
#
# CUDA Environment Variables (set these in your shell if needed):
# export CUDA_HOME=/usr/local/cuda-12.8
# export PATH=$CUDA_HOME/bin:$PATH
# export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH
# export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True  # Better memory management

# ============================================================================
# [DEPRECATED] CHATTERBOX TTS (Replaced by Parler-TTS)
# ============================================================================
# The following Chatterbox settings are deprecated but kept for rollback
# Uncomment and use these if you need to revert to Chatterbox TTS
#
# CHATTERBOX_REFERENCE_VOICE=/path/to/your/reference_voice.wav
# CHATTERBOX_DEVICE=cuda
# CHATTERBOX_EXAGGERATION=0.5
# CHATTERBOX_CFG_WEIGHT=0.5
# CHATTERBOX_CHUNK_MS=50
# CHATTERBOX_TEMPERATURE=0.8
# CHATTERBOX_TOP_P=1.0
# CHATTERBOX_REPETITION_PENALTY=1.2
# CHATTERBOX_SYNTHESIS_TIMEOUT=30
# CHATTERBOX_RETRY_ATTEMPTS=3
# CHATTERBOX_AUDIO_POSTPROCESS=true
# CHATTERBOX_FADE_MS=10
# CHATTERBOX_TRIM_SILENCE=true
# CHATTERBOX_MIN_TEXT_CHARS=20
# CHATTERBOX_STREAM_ON_CLAUSE=true
# CHATTERBOX_SKIP_POSTPROCESS_STREAMING=true
# CHATTERBOX_USE_TOKEN_STREAMING=true
# CHATTERBOX_TOKEN_CHUNK_SIZE=50

# ============================================================================
# EMBEDDED WHISPER TRANSCRIPTION (Real-time Speech-to-Text)
# ============================================================================
# Model: tiny, small, medium, large-v3, distil-large-v3 (recommended)
WHISPER_MODEL=distil-large-v3

# Device: "cuda" (GPU) or "cpu"
WHISPER_DEVICE=cuda

# Compute precision: float16 (fast), float32 (accurate), int8 (memory-efficient)
WHISPER_COMPUTE_TYPE=float16

# Language code (e.g., en, es, fr, de)
WHISPER_LANGUAGE=en

# Voice Activity Detection
WHISPER_USE_VAD=true              # Enable VAD for silence filtering
WHISPER_NO_SPEECH_THRESH=0.65    # Silence threshold (0.0-1.0)

# Transcription behavior
WHISPER_CHUNK_INTERVAL=0.5        # Min seconds before transcription
WHISPER_SAME_OUTPUT_THRESHOLD=5   # Repeated outputs before finalizing

# Logging
TRANSCRIPTION_LOGGING_ENABLED=true # Verbose transcription logs
