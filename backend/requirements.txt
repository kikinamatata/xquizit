fastapi
uvicorn
langchain
langchain-google-genai
langgraph
requests
python-multipart
PyPDF2
python-docx
pydantic
pydantic-settings
python-dotenv
numpy>=1.26.0
scipy>=1.12.0
sse-starlette
nest-asyncio
tenacity
prometheus-client
websockets

# Embedded Whisper Transcription
faster-whisper>=1.0.0
ctranslate2>=4.0.0
onnxruntime>=1.17.0
tokenizers>=0.20.0
huggingface_hub

# Indic Parler-TTS (Indian English Text-to-Speech)
# Install from GitHub with: pip install git+https://github.com/huggingface/parler-tts.git

# Core PyTorch dependencies (GPU-optimized for Linux)
# For CUDA 12.8 support, install with: pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128
# For CPU-only (Windows/macOS), the default pip install works
torch>=2.5.0  # Upgraded from 2.2.0 for CUDA 12.8 support and torch.compile() improvements
torchaudio
transformers==4.46.1
soundfile>=0.12.0
accelerate

# GPU Optimization Dependencies (Linux only)
triton>=2.1.0  # Required for torch.compile() - 4x speedup on Linux (not supported on Windows)
flash-attn>=2.5.0  # Flash Attention 2 for 1.4x speedup (requires CUDA, ~15min compile time)
ninja  # Build dependency for Flash Attention compilation
packaging  # Build dependency for Flash Attention
wheel  # Build dependency

# [DEPRECATED] Chatterbox TTS (kept for rollback, uncomment if needed)
# librosa>=0.10.0
# soundfile>=0.12.0
# safetensors>=0.4.0
# transformers>=4.40.0
# tokenizers>=0.15.0
